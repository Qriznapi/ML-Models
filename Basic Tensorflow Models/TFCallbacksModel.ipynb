{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58bd74fd-80bd-40e5-a334-c7646ac4dfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda1\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "# Load the diabetes dataset\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes_dataset = load_diabetes()\n",
    "\n",
    "# Save the input and target variables\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = diabetes_dataset['data']\n",
    "targets = diabetes_dataset['target']\n",
    "# Split the data set into training and test sets\n",
    "\n",
    "train_data, test_data, train_targets, test_targets = train_test_split(data, targets, test_size=0.1)\n",
    "# Build the model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(train_data.shape[1],)),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)        \n",
    "])\n",
    "# Compile the model\n",
    "\n",
    "model.compile(loss='mse',\n",
    "                optimizer=\"adam\",metrics=[\"mse\",\"mae\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba25c033-b4ea-44c4-a3f2-d6bc5205d2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0020000000474974513.\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0020000000949949026.\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.005000000094994903.\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.009999999888241292.\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.01699999977648258.\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.016999999061226845.\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.025999999061226846.\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.3333333333333333.\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.125.\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.07692307692307693.\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.05555555555555555.\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.043478260869565216.\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.03571428571428571.\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.030303030303030304.\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.02631578947368421.\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.023255813953488372.\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.020833333333333332.\n"
     ]
    }
   ],
   "source": [
    "# Define the learning rate schedule function\n",
    "\n",
    "def lr_function(epoch, lr):\n",
    "    if epoch % 2 == 0:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr + epoch/1000\n",
    "\n",
    "# Train the model\n",
    "\n",
    "history = model.fit(train_data, train_targets, epochs=10,\n",
    "                    callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_function, verbose=1)], verbose=False)\n",
    "\n",
    "# Train the model with a difference schedule\n",
    "\n",
    "history = model.fit(train_data, train_targets, epochs=10,\n",
    "                    callbacks=[tf.keras.callbacks.LearningRateScheduler(lambda x:1/(3+5*x), verbose=1)], \n",
    "                    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5d4bee3-9893-44a6-b376-88faffda82d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27289.589844</td>\n",
       "      <td>146.488708</td>\n",
       "      <td>27289.589844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27214.033203</td>\n",
       "      <td>146.224823</td>\n",
       "      <td>27214.033203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27136.695312</td>\n",
       "      <td>145.958191</td>\n",
       "      <td>27136.695312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27059.490234</td>\n",
       "      <td>145.696579</td>\n",
       "      <td>27059.490234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26984.234375</td>\n",
       "      <td>145.434555</td>\n",
       "      <td>26984.234375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26907.505859</td>\n",
       "      <td>145.172577</td>\n",
       "      <td>26907.505859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26831.583984</td>\n",
       "      <td>144.910446</td>\n",
       "      <td>26831.583984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26755.503906</td>\n",
       "      <td>144.648544</td>\n",
       "      <td>26755.503906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26680.083984</td>\n",
       "      <td>144.388031</td>\n",
       "      <td>26680.083984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26605.023438</td>\n",
       "      <td>144.125137</td>\n",
       "      <td>26605.023438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               loss         mae           mse  val_loss  val_mae  val_mse\n",
       "epoch                                                                    \n",
       "0      27289.589844  146.488708  27289.589844       NaN      NaN      NaN\n",
       "1      27214.033203  146.224823  27214.033203       NaN      NaN      NaN\n",
       "2      27136.695312  145.958191  27136.695312       NaN      NaN      NaN\n",
       "3      27059.490234  145.696579  27059.490234       NaN      NaN      NaN\n",
       "4      26984.234375  145.434555  26984.234375       NaN      NaN      NaN\n",
       "5      26907.505859  145.172577  26907.505859       NaN      NaN      NaN\n",
       "6      26831.583984  144.910446  26831.583984       NaN      NaN      NaN\n",
       "7      26755.503906  144.648544  26755.503906       NaN      NaN      NaN\n",
       "8      26680.083984  144.388031  26680.083984       NaN      NaN      NaN\n",
       "9      26605.023438  144.125137  26605.023438       NaN      NaN      NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with a CSV logger\n",
    "\n",
    "history = model.fit(train_data, train_targets, epochs=10,\n",
    "                    callbacks=[tf.keras.callbacks.CSVLogger(\"results.csv\")], verbose=False)\n",
    "# Load the CSV\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(\"results.csv\", index_col='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac9421b8-2d63-4633-b4c1-746c415715d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1!\n",
      "\n",
      " After batch 0, the loss is 30757.92.\n",
      "\n",
      " After batch 1, the loss is 26227.70.\n",
      "\n",
      " After batch 2, the loss is 27359.75.\n",
      "\n",
      " After batch 3, the loss is 26553.49.\n",
      "Starting Epoch 2!\n",
      "\n",
      " After batch 0, the loss is 25851.21.\n",
      "\n",
      " After batch 1, the loss is 27887.88.\n",
      "\n",
      " After batch 2, the loss is 27193.30.\n",
      "\n",
      " After batch 3, the loss is 26530.51.\n",
      "Starting Epoch 3!\n",
      "\n",
      " After batch 0, the loss is 24327.82.\n",
      "\n",
      " After batch 1, the loss is 23843.34.\n",
      "\n",
      " After batch 2, the loss is 26407.32.\n",
      "\n",
      " After batch 3, the loss is 26507.19.\n",
      "Starting Epoch 4!\n",
      "\n",
      " After batch 0, the loss is 24832.03.\n",
      "\n",
      " After batch 1, the loss is 24061.41.\n",
      "\n",
      " After batch 2, the loss is 25404.41.\n",
      "\n",
      " After batch 3, the loss is 26484.14.\n",
      "Starting Epoch 5!\n",
      "\n",
      " After batch 0, the loss is 28660.60.\n",
      "\n",
      " After batch 1, the loss is 26717.54.\n",
      "\n",
      " After batch 2, the loss is 26426.69.\n",
      "\n",
      " After batch 3, the loss is 26461.49.\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "# Print the epoch number at the beginning of each epoch\n",
    "\n",
    "epoch_callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_epoch_begin=lambda epoch,logs: print('Starting Epoch {}!'.format(epoch+1)))\n",
    "# Print the loss at the end of each batch\n",
    "\n",
    "batch_loss_callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_batch_end=lambda batch,logs: print('\\n After batch {}, the loss is {:7.2f}.'.format(batch, logs['loss'])))\n",
    "# Inform that training is finished\n",
    "\n",
    "train_finish_callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_train_end=lambda logs: print('Training finished!'))\n",
    "\n",
    "# Train the model with the lambda callbacks\n",
    "\n",
    "history = model.fit(train_data, train_targets, epochs=5, batch_size=100,\n",
    "                    callbacks=[epoch_callback, batch_loss_callback,train_finish_callback], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f12552de-e488-45a9-81dd-311003e73784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the ReduceLROnPlateau callback\n",
    "\n",
    "history = model.fit(train_data, train_targets, epochs=100, batch_size=100,\n",
    "                    callbacks=[tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                        monitor=\"loss\",factor=0.2, verbose=1)], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb07c9d-2546-42a8-85c5-4add45dd3df2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
